df[colnames(datos_consolidados)] <- lapply(df[colnames(datos_consolidados)], as.integer)
# Filtrar los resultados de VRS
df_vrs <- resultados_in[["original"]][[as.character(year)]][["data"]][, c("IdEstablecimiento", "vrs")] %>%
rename("idEstablecimiento" = "IdEstablecimiento")
print("2")
#print(head(df_vrs))
df_w_vrs <- df %>%
filter(idEstablecimiento %in% df_vrs$idEstablecimiento)
# Combinar los DataFrames
df_merged_original <- merge(df_w_vrs, df_vrs, by = "idEstablecimiento", all.x = TRUE)
#df_merged_clean <- df_merged_original[,-1]
df_merged_clean <- df_merged_original[, colSums(is.na(df_merged_clean)) == 0]
correlaciones <- cor(df_merged_clean[,-1])["vrs", ]
correlaciones <- correlaciones[!names(correlaciones) %in% "vrs"]
correlaciones_ordenadas <- sort(abs(correlaciones), decreasing = TRUE)
top_correlacion <- head(correlaciones_ordenadas, n=50)
top_variables <- names(top_correlacion)
columnas_a_incluir <- c("vrs", top_variables)
# Crear el DataFrame con las variables seleccionadas
df_top <- df_merged_clean[, columnas_a_incluir]
# PROBANDO RANDOM FOREST
set.seed(123)  # Para reproducibilidad
library(caret)
trainIndex <- createDataPartition(df_top$vrs, p = 0.7, list = FALSE)
trainData <- df_top[trainIndex, ]
testData <- df_top[-trainIndex, ]
library(randomForest)
# Ajustar el modelo de Random Forest
modelo_rf <- randomForest(vrs ~ .,
data = trainData,
importance = TRUE,
ntree = 500)
# Ver el modelo ajustado
print(modelo_rf)
# Predicciones en el conjunto de prueba
predicciones <- predict(modelo_rf, newdata = testData)
# Evaluar el rendimiento
library(Metrics)
r2 <- R2(predicciones, testData$vrs)
rmse <- rmse(predicciones, testData$eficiencia)
cat("R²:", r2, "\nRMSE:", rmse)
# Importancia de las variables
importancia <- importance(modelo_rf)
print(importancia)
# Graficar la importancia
varImpPlot(modelo_rf)
return(importancia[order(importancia[, "%IncMSE"], decreasing = TRUE)][1:50, ])
}
test_2014 <- analize_rf(2014,resultados_in = resultados_in)
analize_rf <- function(year, resultados_in){
#year <- 2014
data_path <- paste0("data/", year, "/", year, "_consolidated_data.csv")
print(data_path)
# Leer los datos consolidados
datos_consolidados <- read.table(data_path, sep = ";", header = TRUE)
df <- datos_consolidados
#print(head(df))
# Convertir columnas a enteros
df[colnames(datos_consolidados)] <- lapply(df[colnames(datos_consolidados)], as.integer)
# Filtrar los resultados de VRS
df_vrs <- resultados_in[["original"]][[as.character(year)]][["data"]][, c("IdEstablecimiento", "vrs")] %>%
rename("idEstablecimiento" = "IdEstablecimiento")
print("2")
#print(head(df_vrs))
df_w_vrs <- df %>%
filter(idEstablecimiento %in% df_vrs$idEstablecimiento)
# Combinar los DataFrames
df_merged_original <- merge(df_w_vrs, df_vrs, by = "idEstablecimiento", all.x = TRUE)
#df_merged_clean <- df_merged_original[,-1]
df_merged_clean <- df_merged_original[, colSums(is.na(df_merged_clean)) == 0]
correlaciones <- cor(df_merged_clean[,-1])["vrs", ]
correlaciones <- correlaciones[!names(correlaciones) %in% "vrs"]
correlaciones_ordenadas <- sort(abs(correlaciones), decreasing = TRUE)
top_correlacion <- head(correlaciones_ordenadas, n=50)
top_variables <- names(top_correlacion)
columnas_a_incluir <- c("vrs", top_variables)
# Crear el DataFrame con las variables seleccionadas
df_top <- df_merged_clean[, columnas_a_incluir]
# PROBANDO RANDOM FOREST
set.seed(123)  # Para reproducibilidad
library(caret)
trainIndex <- createDataPartition(df_top$vrs, p = 0.7, list = FALSE)
trainData <- df_top[trainIndex, ]
testData <- df_top[-trainIndex, ]
library(randomForest)
# Ajustar el modelo de Random Forest
modelo_rf <- randomForest(vrs ~ .,
data = trainData,
importance = TRUE,
ntree = 500)
# Ver el modelo ajustado
print(modelo_rf)
# Predicciones en el conjunto de prueba
predicciones <- predict(modelo_rf, newdata = testData)
# Evaluar el rendimiento
library(Metrics)
r2 <- R2(predicciones, testData$vrs)
rmse <- rmse(predicciones, testData$eficiencia)
cat("R²:", r2, "\nRMSE:", rmse)
# Importancia de las variables
importancia <- importance(modelo_rf)
print(importancia)
# Graficar la importancia
varImpPlot(modelo_rf)
return(importancia)
}
test_2014 <- analize_rf(2014,resultados_in = resultados_in)
test_2015 <- analize_rf(2015,resultados_in = resultados_in)
test_2016 <- analize_rf(2016,resultados_in = resultados_in)
top_50_2014 <- test_2014[order(test_2014[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2015 <- test_2015[order(test_2015[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2016 <- test_2016[order(test_2016[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2017 <- test_2017[order(test_2017[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2018 <- test_2018[order(test_2018[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2019 <- test_2019[order(test_2019[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2020 <- test_2020[order(test_2020[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
# Extraer nombres de las variables
variables_2014 <- rownames(top_50_2014)
variables_2015 <- rownames(top_50_2015)
variables_2016 <- rownames(top_50_2016)
variables_2017 <- rownames(top_50_2017)
variables_2018 <- rownames(top_50_2018)
variables_2019 <- rownames(top_50_2019)
variables_2020 <- rownames(top_50_2020)
# Combinar todas las variables en una sola lista
todas_las_variables <- c(variables_2014, variables_2015, variables_2016,
variables_2017, variables_2018, variables_2019, variables_2020)
top_50_2014 <- test_2014[order(test_2014[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2015 <- test_2015[order(test_2015[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2016 <- test_2016[order(test_2016[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
test_2016 <- analize_rf(2016,resultados_in = resultados_in)
test_2017 <- analize_rf(2017,resultados_in = resultados_in)
test_2018 <- analize_rf(2018,resultados_in = resultados_in)
analize_rf <- function(year, resultados_in){
#year <- 2014
data_path <- paste0("data/", year, "/", year, "_consolidated_data.csv")
print(data_path)
# Leer los datos consolidados
datos_consolidados <- read.table(data_path, sep = ";", header = TRUE)
df <- datos_consolidados
#print(head(df))
# Convertir columnas a enteros
df[colnames(datos_consolidados)] <- lapply(df[colnames(datos_consolidados)], as.integer)
# Filtrar los resultados de VRS
df_vrs <- resultados_in[["original"]][[as.character(year)]][["data"]][, c("IdEstablecimiento", "vrs")] %>%
rename("idEstablecimiento" = "IdEstablecimiento")
print("2")
#print(head(df_vrs))
df_w_vrs <- df %>%
filter(idEstablecimiento %in% df_vrs$idEstablecimiento)
# Combinar los DataFrames
df_merged_original <- merge(df_w_vrs, df_vrs, by = "idEstablecimiento", all.x = TRUE)
#df_merged_clean <- df_merged_original[,-1]
print("VARIABLES QUE NO COINCIDEN")
no_coinciden <- setdiff(names(df_merged_original), names(df_merged_clean))
no_coinciden
df_merged_clean <- df_merged_original[, colSums(is.na(df_merged_clean)) == 0]
correlaciones <- cor(df_merged_clean[,-1])["vrs", ]
correlaciones <- correlaciones[!names(correlaciones) %in% "vrs"]
correlaciones_ordenadas <- sort(abs(correlaciones), decreasing = TRUE)
top_correlacion <- head(correlaciones_ordenadas, n=50)
top_variables <- names(top_correlacion)
columnas_a_incluir <- c("vrs", top_variables)
# Crear el DataFrame con las variables seleccionadas
df_top <- df_merged_clean[, columnas_a_incluir]
# PROBANDO RANDOM FOREST
set.seed(123)  # Para reproducibilidad
library(caret)
trainIndex <- createDataPartition(df_top$vrs, p = 0.7, list = FALSE)
trainData <- df_top[trainIndex, ]
testData <- df_top[-trainIndex, ]
library(randomForest)
# Ajustar el modelo de Random Forest
modelo_rf <- randomForest(vrs ~ .,
data = trainData,
importance = TRUE,
ntree = 500)
# Ver el modelo ajustado
print(modelo_rf)
# Predicciones en el conjunto de prueba
predicciones <- predict(modelo_rf, newdata = testData)
# Evaluar el rendimiento
library(Metrics)
r2 <- R2(predicciones, testData$vrs)
rmse <- rmse(predicciones, testData$eficiencia)
cat("R²:", r2, "\nRMSE:", rmse)
# Importancia de las variables
importancia <- importance(modelo_rf)
print(importancia)
# Graficar la importancia
varImpPlot(modelo_rf)
return(importancia)
}
analize_rf <- function(year, resultados_in){
#year <- 2014
data_path <- paste0("data/", year, "/", year, "_consolidated_data.csv")
print(data_path)
# Leer los datos consolidados
datos_consolidados <- read.table(data_path, sep = ";", header = TRUE)
df <- datos_consolidados
#print(head(df))
# Convertir columnas a enteros
df[colnames(datos_consolidados)] <- lapply(df[colnames(datos_consolidados)], as.integer)
# Filtrar los resultados de VRS
df_vrs <- resultados_in[["original"]][[as.character(year)]][["data"]][, c("IdEstablecimiento", "vrs")] %>%
rename("idEstablecimiento" = "IdEstablecimiento")
print("2")
#print(head(df_vrs))
df_w_vrs <- df %>%
filter(idEstablecimiento %in% df_vrs$idEstablecimiento)
# Combinar los DataFrames
df_merged_original <- merge(df_w_vrs, df_vrs, by = "idEstablecimiento", all.x = TRUE)
#df_merged_clean <- df_merged_original[,-1]
print("VARIABLES QUE NO COINCIDEN")
no_coinciden <- setdiff(names(df_merged_original), names(df_merged_clean))
no_coinciden
df_merged_clean <- df_merged_original[, colSums(is.na(df_merged_clean)) == 0]
correlaciones <- cor(df_merged_clean[,-1])["vrs", ]
correlaciones <- correlaciones[!names(correlaciones) %in% "vrs"]
correlaciones_ordenadas <- sort(abs(correlaciones), decreasing = TRUE)
top_correlacion <- head(correlaciones_ordenadas, n=50)
top_variables <- names(top_correlacion)
columnas_a_incluir <- c("vrs", top_variables)
# Crear el DataFrame con las variables seleccionadas
df_top <- df_merged_clean[, columnas_a_incluir]
# PROBANDO RANDOM FOREST
set.seed(123)  # Para reproducibilidad
library(caret)
trainIndex <- createDataPartition(df_top$vrs, p = 0.7, list = FALSE)
trainData <- df_top[trainIndex, ]
testData <- df_top[-trainIndex, ]
library(randomForest)
# Ajustar el modelo de Random Forest
modelo_rf <- randomForest(vrs ~ .,
data = trainData,
importance = TRUE,
ntree = 500)
# Ver el modelo ajustado
print(modelo_rf)
# Predicciones en el conjunto de prueba
predicciones <- predict(modelo_rf, newdata = testData)
# Evaluar el rendimiento
library(Metrics)
r2 <- R2(predicciones, testData$vrs)
rmse <- rmse(predicciones, testData$eficiencia)
cat("R²:", r2, "\nRMSE:", rmse)
# Importancia de las variables
importancia <- importance(modelo_rf)
print(importancia)
# Graficar la importancia
varImpPlot(modelo_rf)
return(importancia)
}
test_2014 <- analize_rf(2014,resultados_in = resultados_in)
analize_rf <- function(year, resultados_in){
#year <- 2014
data_path <- paste0("data/", year, "/", year, "_consolidated_data.csv")
print(data_path)
# Leer los datos consolidados
datos_consolidados <- read.table(data_path, sep = ";", header = TRUE)
df <- datos_consolidados
#print(head(df))
# Convertir columnas a enteros
df[colnames(datos_consolidados)] <- lapply(df[colnames(datos_consolidados)], as.integer)
# Filtrar los resultados de VRS
df_vrs <- resultados_in[["original"]][[as.character(year)]][["data"]][, c("IdEstablecimiento", "vrs")] %>%
rename("idEstablecimiento" = "IdEstablecimiento")
print("2")
#print(head(df_vrs))
df_w_vrs <- df %>%
filter(idEstablecimiento %in% df_vrs$idEstablecimiento)
# Combinar los DataFrames
df_merged_original <- merge(df_w_vrs, df_vrs, by = "idEstablecimiento", all.x = TRUE)
#df_merged_clean <- df_merged_original[,-1]
print("VARIABLES QUE NO COINCIDEN")
no_coinciden <- setdiff(names(df_merged_original), names(df_merged_clean))
no_coinciden
df_merged_clean <- df_merged_original[, colSums(is.na(df_merged_clean)) == 0]
correlaciones <- cor(df_merged_clean[,-1])["vrs", ]
correlaciones <- correlaciones[!names(correlaciones) %in% "vrs"]
correlaciones_ordenadas <- sort(abs(correlaciones), decreasing = TRUE)
top_correlacion <- head(correlaciones_ordenadas, n=50)
top_variables <- names(top_correlacion)
columnas_a_incluir <- c("vrs", top_variables)
# Crear el DataFrame con las variables seleccionadas
df_top <- df_merged_clean[, columnas_a_incluir]
# PROBANDO RANDOM FOREST
set.seed(123)  # Para reproducibilidad
library(caret)
trainIndex <- createDataPartition(df_top$vrs, p = 0.7, list = FALSE)
trainData <- df_top[trainIndex, ]
testData <- df_top[-trainIndex, ]
library(randomForest)
# Ajustar el modelo de Random Forest
modelo_rf <- randomForest(vrs ~ .,
data = trainData,
importance = TRUE,
ntree = 500)
# Ver el modelo ajustado
#print(modelo_rf)
# Predicciones en el conjunto de prueba
predicciones <- predict(modelo_rf, newdata = testData)
# Evaluar el rendimiento
library(Metrics)
r2 <- R2(predicciones, testData$vrs)
rmse <- rmse(predicciones, testData$eficiencia)
cat("R²:", r2, "\nRMSE:", rmse)
# Importancia de las variables
importancia <- importance(modelo_rf)
#print(importancia)
# Graficar la importancia
varImpPlot(modelo_rf)
return(importancia)
}
test_2014 <- analize_rf(2014,resultados_in = resultados_in)
View(test_2014)
test_2015 <- analize_rf(2015,resultados_in = resultados_in)
test_2016 <- analize_rf(2016,resultados_in = resultados_in)
analize_rf <- function(year, resultados_in){
#year <- 2014
data_path <- paste0("data/", year, "/", year, "_consolidated_data.csv")
print(data_path)
# Leer los datos consolidados
datos_consolidados <- read.table(data_path, sep = ";", header = TRUE)
df <- datos_consolidados
#print(head(df))
# Convertir columnas a enteros
df[colnames(datos_consolidados)] <- lapply(df[colnames(datos_consolidados)], as.integer)
# Filtrar los resultados de VRS
df_vrs <- resultados_in[["original"]][[as.character(year)]][["data"]][, c("IdEstablecimiento", "vrs")] %>%
rename("idEstablecimiento" = "IdEstablecimiento")
print("2")
#print(head(df_vrs))
df_w_vrs <- df %>%
filter(idEstablecimiento %in% df_vrs$idEstablecimiento)
# Combinar los DataFrames
df_merged_original <- merge(df_w_vrs, df_vrs, by = "idEstablecimiento", all.x = TRUE)
#df_merged_clean <- df_merged_original[,-1]
print("VARIABLES QUE NO COINCIDEN")
no_coinciden <- setdiff(names(df_merged_original), names(df_merged_clean))
print(no_coinciden)
df_merged_clean <- df_merged_original[, colSums(is.na(df_merged_original)) == 0]
correlaciones <- cor(df_merged_clean[,-1])["vrs", ]
correlaciones <- correlaciones[!names(correlaciones) %in% "vrs"]
correlaciones_ordenadas <- sort(abs(correlaciones), decreasing = TRUE)
top_correlacion <- head(correlaciones_ordenadas, n=50)
top_variables <- names(top_correlacion)
columnas_a_incluir <- c("vrs", top_variables)
# Crear el DataFrame con las variables seleccionadas
df_top <- df_merged_clean[, columnas_a_incluir]
# PROBANDO RANDOM FOREST
set.seed(123)  # Para reproducibilidad
library(caret)
trainIndex <- createDataPartition(df_top$vrs, p = 0.7, list = FALSE)
trainData <- df_top[trainIndex, ]
testData <- df_top[-trainIndex, ]
library(randomForest)
# Ajustar el modelo de Random Forest
modelo_rf <- randomForest(vrs ~ .,
data = trainData,
importance = TRUE,
ntree = 500)
# Ver el modelo ajustado
#print(modelo_rf)
# Predicciones en el conjunto de prueba
predicciones <- predict(modelo_rf, newdata = testData)
# Evaluar el rendimiento
library(Metrics)
r2 <- R2(predicciones, testData$vrs)
rmse <- rmse(predicciones, testData$eficiencia)
cat("R²:", r2, "\nRMSE:", rmse)
# Importancia de las variables
importancia <- importance(modelo_rf)
#print(importancia)
# Graficar la importancia
varImpPlot(modelo_rf)
return(importancia)
}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("functions.R")
source("graphics.R")
# -------------------------------------------- #
#  CONSOLIDADO DE DATOS POR AÑO
# -------------------------------------------- #
# ==============================================
anios <- c("2014", "2015", "2016", "2017", "2018", "2019","2020")
datos_iniciales <- list(
"2014" = consolidar_datos_por_anio(2014),
"2015" = consolidar_datos_por_anio(2015),
"2016" = consolidar_datos_por_anio(2016),
"2017" = consolidar_datos_por_anio(2017),
"2018" = consolidar_datos_por_anio(2018),
"2019" = consolidar_datos_por_anio(2019),
"2020" = consolidar_datos_por_anio(2020)
)
# Encontrar las DMUs comunes en todos los años y filtrar los datos para incluir solo esas DMUs
dmus_comunes <- Reduce(intersect, lapply(datos_iniciales, `[[`, "IdEstablecimiento"))
datos <- lapply(datos_iniciales, function(data) data[data$IdEstablecimiento %in% dmus_comunes, ])
# -------------------------------------------- #
# SENSIBILIDAD
# -------------------------------------------- #
# ==============================================
# -------------------------------------------- #
#  CÁLCULO DEA - ELIMINACION EFICIENTES
# -------------------------------------------- #
#  INPUT
resultados_in <- resultados_iteracion(datos, "io")
test_2014 <- analize_rf(2014,resultados_in = resultados_in)
analize_rf <- function(year, resultados_in){
#year <- 2014
data_path <- paste0("data/", year, "/", year, "_consolidated_data.csv")
print(data_path)
# Leer los datos consolidados
datos_consolidados <- read.table(data_path, sep = ";", header = TRUE)
df <- datos_consolidados
#print(head(df))
# Convertir columnas a enteros
df[colnames(datos_consolidados)] <- lapply(df[colnames(datos_consolidados)], as.integer)
# Filtrar los resultados de VRS
df_vrs <- resultados_in[["original"]][[as.character(year)]][["data"]][, c("IdEstablecimiento", "vrs")] %>%
rename("idEstablecimiento" = "IdEstablecimiento")
print("2")
#print(head(df_vrs))
df_w_vrs <- df %>%
filter(idEstablecimiento %in% df_vrs$idEstablecimiento)
# Combinar los DataFrames
df_merged_original <- merge(df_w_vrs, df_vrs, by = "idEstablecimiento", all.x = TRUE)
#df_merged_clean <- df_merged_original[,-1]
#print("VARIABLES QUE NO COINCIDEN")
#no_coinciden <- setdiff(names(df_merged_original), names(df_merged_clean))
#print(no_coinciden)
df_merged_clean <- df_merged_original[, colSums(is.na(df_merged_original)) == 0]
correlaciones <- cor(df_merged_clean[,-1])["vrs", ]
correlaciones <- correlaciones[!names(correlaciones) %in% "vrs"]
correlaciones_ordenadas <- sort(abs(correlaciones), decreasing = TRUE)
top_correlacion <- head(correlaciones_ordenadas, n=50)
top_variables <- names(top_correlacion)
columnas_a_incluir <- c("vrs", top_variables)
# Crear el DataFrame con las variables seleccionadas
df_top <- df_merged_clean[, columnas_a_incluir]
# PROBANDO RANDOM FOREST
set.seed(123)  # Para reproducibilidad
library(caret)
trainIndex <- createDataPartition(df_top$vrs, p = 0.7, list = FALSE)
trainData <- df_top[trainIndex, ]
testData <- df_top[-trainIndex, ]
library(randomForest)
# Ajustar el modelo de Random Forest
modelo_rf <- randomForest(vrs ~ .,
data = trainData,
importance = TRUE,
ntree = 500)
# Ver el modelo ajustado
#print(modelo_rf)
# Predicciones en el conjunto de prueba
predicciones <- predict(modelo_rf, newdata = testData)
# Evaluar el rendimiento
library(Metrics)
r2 <- R2(predicciones, testData$vrs)
rmse <- rmse(predicciones, testData$eficiencia)
cat("R²:", r2, "\nRMSE:", rmse)
# Importancia de las variables
importancia <- importance(modelo_rf)
#print(importancia)
# Graficar la importancia
varImpPlot(modelo_rf)
return(importancia)
}
test_2014 <- analize_rf(2014,resultados_in = resultados_in)
test_2015 <- analize_rf(2015,resultados_in = resultados_in)
test_2016 <- analize_rf(2016,resultados_in = resultados_in)
test_2017 <- analize_rf(2017,resultados_in = resultados_in)
test_2018 <- analize_rf(2018,resultados_in = resultados_in)
test_2019 <- analize_rf(2019,resultados_in = resultados_in)
test_2020 <- analize_rf(2020,resultados_in = resultados_in)
top_50_2014 <- test_2014[order(test_2014[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2015 <- test_2015[order(test_2015[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2016 <- test_2016[order(test_2016[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2017 <- test_2017[order(test_2017[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2018 <- test_2018[order(test_2018[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2019 <- test_2019[order(test_2019[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
top_50_2020 <- test_2020[order(test_2020[, "%IncMSE"], decreasing = TRUE), ][1:50, ]
# Extraer nombres de las variables
variables_2014 <- rownames(top_50_2014)
variables_2015 <- rownames(top_50_2015)
variables_2016 <- rownames(top_50_2016)
variables_2017 <- rownames(top_50_2017)
variables_2018 <- rownames(top_50_2018)
variables_2019 <- rownames(top_50_2019)
variables_2020 <- rownames(top_50_2020)
# Combinar todas las variables en una sola lista
todas_las_variables <- c(variables_2014, variables_2015, variables_2016,
variables_2017, variables_2018, variables_2019, variables_2020)
# Calcular las frecuencias de cada variable
frecuencias <- table(todas_las_variables)
# Ordenar por frecuencia en orden descendente
frecuencias_ordenadas <- sort(frecuencias, decreasing = TRUE)
# Mostrar las variables con sus frecuencias
print(frecuencias_ordenadas)
# Opcional: filtrar las variables que se repiten en al menos dos años
frecuencias_filtradas <- frecuencias_ordenadas[frecuencias_ordenadas > 1]
print("Variables que se repiten en al menos dos años:")
print(frecuencias_filtradas)
library(ggplot2)
# Convertir las frecuencias en un dataframe
df_frecuencias <- as.data.frame(frecuencias_filtradas)
colnames(df_frecuencias) <- c("Variable", "Frecuencia")
# Graficar las frecuencias
ggplot(df_frecuencias, aes(x = reorder(Variable, -Frecuencia), y = Frecuencia)) +
geom_bar(stat = "identity", fill = "blue") +
labs(title = "Frecuencia de variables entre años", x = "Variable", y = "Frecuencia") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
